## 데이터 출처: [Home Credit Default Risk](https://www.kaggle.com/c/home-credit-default-risk/data)

## 프로젝트 개요

**[원문]**

Many people struggle to get loans due to insufficient or non-existent credit histories. And, unfortunately, this population is often taken advantage of by untrustworthy lenders.

Home Credit Group

Home Credit strives to broaden financial inclusion for the unbanked population by providing a positive and safe borrowing experience. In order to make sure this underserved population has a positive loan experience, Home Credit makes use of a variety of alternative data--including telco and transactional information--to predict their clients' repayment abilities.


While Home Credit is currently using various statistical and machine learning methods to make these predictions, they're challenging Kagglers to help them unlock the full potential of their data. Doing so will ensure that clients capable of repayment are not rejected and that loans are given with a principal, maturity, and repayment calendar that will empower their clients to be successful.

**[번역]**

많은 사람들은 신용 기록이 불충분하거나 존재하지 않아 대출을 받기 위해 애를 씁니다. 불행히도,이 인구는 종종 신뢰할 수없는 대출 기관에 의해 이용됩니다.

주택 신용 그룹

주택 신용 기관(Home Credit)은 긍정적이고 안전한 차용 경험을 제공함으로써 비은행 인구를위한 재정적 포용을 확대하기 위해 노력합니다. 이 소외된 인구가 긍정적 인 대출 경험을 갖도록하기 위해 주택 신용 기관(Home Credit)은 고객의 상환 능력을 예측하기 위해 전화 및 거래 정보를 포함한 다양한 대체 데이터를 사용합니다.

주택 신용 기관(Home Credit)은 여러분의 다양한 통계 데이터 분석 능력과 머신러닝 방법을 활용하여, 고객이 은행 부채 상환능력에 대한 예측을 진행해 주세요. 그렇게하면 상환 가능한 고객이 거부되지 않고 성공적으로 원금, 만기 및 상환 일정에 따라 대출을 받을 수 있습니다.

## 프로젝트 목표
1. `pandas`, `numpy`, `scikit-learn` 패키지를 활용하여 데이터 병합, 전처리, 피처 공학(feature engineering)을 진행합니다.
2. 데이터에 대한 시각화를 통해 주요(Key) 데이터를 추출합니다.
3. 머신러닝 모델을 만들고 예측 합니다.
4. Kaggle에 제출해보고, 목표 점수까지 획득할 수 있도록 수정 및 보완합니다.


## 프로젝트 구성
* 데이터 로드 (load data)
* 데이터 시각화 (visualization)
* 데이터 전처리 (pre-processing)
* 머신러닝을 활용하여 baseline 모델링 (modeling for baseline)
* 평가지표 생성 (evalutation)
* 모델 앙상블, 데이터 전처리 개선으로 모델의 성능을 업그레이드 하여, 목표 점수에 도달



```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings 
from IPython.display import Image

warnings.filterwarnings('ignore')
%matplotlib inline

SEED = 34
```

## 데이터 살펴보기


```python
Image('data/home_credit.png')
```




    
![png](output_3_0.png)
    



큰일입니다. 복잡한 고객의 채무관계 파악을 위해서 주택 신용 기관(Home Credit)에서 고객 정보를 여러 파일에 저장했습니다. (실제 사례에서도 당연히, 이렇게 데이터들이 산재되어 있습니다.)

우리는, 이 복잡한 데이터를 분석하기 쉽도록 하나의 **데이터프레임(DataFrame)** 에 `merge` 하는 작업과 전처리(pre-processing)하는 과정을 진행하겠습니다.

**[중요]**

여러 개의 파일들을 하나의 데이터프레임으로 `merge` 할 때, `merge`의 중심이 되는 ID 값이 위의 도표에 친절히 나와있습니다.

너무 걱정 마세요! 제가 예제를 한 번 보여 드리면, 쉽게 따라 하실 수 있으니깐요.

## 파일에 대한 설명

**application_train.csv**, **application_test.csv**

- 2개의 파일이 바로 메인이 되는 파일입니다. 
- 제공되는 다른 파일 정보의 **중심이 되는 데이터**를 포함하고 있습니다. 
- 하나의 행은 데이터 샘플에서 하나의 대출을 의미합니다.

**bureau.csv**

- 신용 기관 (Credit Bureau) 에 보고된 다른 금융 기관에서 제공한 모든 고객의 이전 신용 정보를 포함합니다. (고객이 이전에 대출이 있는 경우)
- 샘플의 모든 대출에는 신청 날짜 이전에 고객이 신용 관리국에 보유한 크레딧 수만큼의 행이 있습니다.

**bureau_balance.csv**

- 신용 기관 (Credit Bureau)에서 이전 신용의 월별 잔액을 나타냅니다.

**POS_CASH_balance.csv**

- 이전 POS (판매 시점) 및 신청자가 주택 신용으로 보유한 현금 대출의 월별 잔액 스냅 샷입니다.

**credit_card_balance.csv**

- 신청자가 주택 신용으로 보유한 이전 시용카드의 월별 잔액 스냅샷입니다.

**previous_application.csv**

- 샘플에 대출이있는 고객의 주택 신용 대출에 대한 모든 이전 신청.

**installments_payments.csv**

- 샘플의 대출과 관련하여 이전에 지불한 주택 신용에 대한 상환 내역.

## Load Files


```python
train = pd.read_csv('data/application_train.csv')
test = pd.read_csv('data/application_test.csv')
```


```python
train.shape, test.shape
```




    ((307511, 122), (48744, 121))




```python
train
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>...</th>
      <th>FLAG_DOCUMENT_18</th>
      <th>FLAG_DOCUMENT_19</th>
      <th>FLAG_DOCUMENT_20</th>
      <th>FLAG_DOCUMENT_21</th>
      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>
      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>
      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>
      <th>AMT_REQ_CREDIT_BUREAU_MON</th>
      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>
      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100002</td>
      <td>1</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>406597.5</td>
      <td>24700.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100003</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>270000.0</td>
      <td>1293502.5</td>
      <td>35698.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100004</td>
      <td>0</td>
      <td>Revolving loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>67500.0</td>
      <td>135000.0</td>
      <td>6750.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100006</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>312682.5</td>
      <td>29686.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100007</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>121500.0</td>
      <td>513000.0</td>
      <td>21865.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>307506</td>
      <td>456251</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>157500.0</td>
      <td>254700.0</td>
      <td>27558.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>307507</td>
      <td>456252</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>72000.0</td>
      <td>269550.0</td>
      <td>12001.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>307508</td>
      <td>456253</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>153000.0</td>
      <td>677664.0</td>
      <td>29979.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>307509</td>
      <td>456254</td>
      <td>1</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>171000.0</td>
      <td>370107.0</td>
      <td>20205.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>307510</td>
      <td>456255</td>
      <td>0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>157500.0</td>
      <td>675000.0</td>
      <td>49117.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>307511 rows × 122 columns</p>
</div>



**`TARGET` 컬럼**

우리가 예측해야할 `label`입니다.


```python
train['TARGET'].value_counts()
```




    0    282686
    1     24825
    Name: TARGET, dtype: int64



`all_data`라는 변수에 `train` 데이터와 `test` 데이터를 합쳐 줍니다.

전처리를 위하여 임시로 합쳐줍니다. 나중에 다시 train/test 로 분할 해야하기 때문에, 순서가 섞이면 안됩니다.


```python
all_data = pd.concat([train, test], sort=False)
```

## 데이터 구조도

자주 데이터 구조도를 확인해가면서 **전처리 작업**을 진행합니다.

필요하면 별도의 창으로 띄워 놓거나, 프린트해서 보면서 풀어나가는 것도 방법입니다.


```python
Image('data/home_credit.png')
```




    
![png](output_18_0.png)
    



## 전처리

### STEP 1. Bureau & Bureau Balance 데이터 병합

`bureau.csv` 파일부터 차근차근 데이터를 살펴보겠습니다.


```python
bureau = pd.read_csv('data/bureau.csv')
print(bureau.shape)
bureau.head()
```

    (1716428, 17)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>SK_ID_BUREAU</th>
      <th>CREDIT_ACTIVE</th>
      <th>CREDIT_CURRENCY</th>
      <th>DAYS_CREDIT</th>
      <th>CREDIT_DAY_OVERDUE</th>
      <th>DAYS_CREDIT_ENDDATE</th>
      <th>DAYS_ENDDATE_FACT</th>
      <th>AMT_CREDIT_MAX_OVERDUE</th>
      <th>CNT_CREDIT_PROLONG</th>
      <th>AMT_CREDIT_SUM</th>
      <th>AMT_CREDIT_SUM_DEBT</th>
      <th>AMT_CREDIT_SUM_LIMIT</th>
      <th>AMT_CREDIT_SUM_OVERDUE</th>
      <th>CREDIT_TYPE</th>
      <th>DAYS_CREDIT_UPDATE</th>
      <th>AMT_ANNUITY</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>215354</td>
      <td>5714462</td>
      <td>Closed</td>
      <td>currency 1</td>
      <td>-497</td>
      <td>0</td>
      <td>-153.0</td>
      <td>-153.0</td>
      <td>NaN</td>
      <td>0</td>
      <td>91323.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Consumer credit</td>
      <td>-131</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>1</td>
      <td>215354</td>
      <td>5714463</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-208</td>
      <td>0</td>
      <td>1075.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>225000.0</td>
      <td>171342.0</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Credit card</td>
      <td>-20</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2</td>
      <td>215354</td>
      <td>5714464</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-203</td>
      <td>0</td>
      <td>528.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>464323.5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Consumer credit</td>
      <td>-16</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>3</td>
      <td>215354</td>
      <td>5714465</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-203</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>90000.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Credit card</td>
      <td>-16</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>215354</td>
      <td>5714466</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-629</td>
      <td>0</td>
      <td>1197.0</td>
      <td>NaN</td>
      <td>77674.5</td>
      <td>0</td>
      <td>2700000.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>Consumer credit</td>
      <td>-21</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
bureau_balance = pd.read_csv('data/bureau_balance.csv')
print(bureau_balance.shape)
bureau_balance.head()
```

    (27299925, 3)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_BUREAU</th>
      <th>MONTHS_BALANCE</th>
      <th>STATUS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>5715448</td>
      <td>0</td>
      <td>C</td>
    </tr>
    <tr>
      <td>1</td>
      <td>5715448</td>
      <td>-1</td>
      <td>C</td>
    </tr>
    <tr>
      <td>2</td>
      <td>5715448</td>
      <td>-2</td>
      <td>C</td>
    </tr>
    <tr>
      <td>3</td>
      <td>5715448</td>
      <td>-3</td>
      <td>C</td>
    </tr>
    <tr>
      <td>4</td>
      <td>5715448</td>
      <td>-4</td>
      <td>C</td>
    </tr>
  </tbody>
</table>
</div>



`SK_ID_BUREAU`로 bureau_balance 데이터와 bureau를 병합해주겠습니다.

하지만, bureau_balance의 `SK_ID_BUREAU` 키 값이 여러개 행을 포함합니다.

그렇기 때문에, 우리는 `groupby`를 통해 하나의 `SK_ID_BUREAU`에 대한 다양한 통계 정보를 bureau에 병합해주도록 하겠습니다.


```python
right = bureau_balance.groupby('SK_ID_BUREAU')['MONTHS_BALANCE'] \
            .agg(['sum', 'count', 'mean', 'std', 'min', 'max', 'median'])
```


```python
right.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
    </tr>
    <tr>
      <th>SK_ID_BUREAU</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>5001709</td>
      <td>-4656</td>
      <td>97</td>
      <td>-48.0</td>
      <td>28.145456</td>
      <td>-96</td>
      <td>0</td>
      <td>-48.0</td>
    </tr>
    <tr>
      <td>5001710</td>
      <td>-3403</td>
      <td>83</td>
      <td>-41.0</td>
      <td>24.103942</td>
      <td>-82</td>
      <td>0</td>
      <td>-41.0</td>
    </tr>
    <tr>
      <td>5001711</td>
      <td>-6</td>
      <td>4</td>
      <td>-1.5</td>
      <td>1.290994</td>
      <td>-3</td>
      <td>0</td>
      <td>-1.5</td>
    </tr>
    <tr>
      <td>5001712</td>
      <td>-171</td>
      <td>19</td>
      <td>-9.0</td>
      <td>5.627314</td>
      <td>-18</td>
      <td>0</td>
      <td>-9.0</td>
    </tr>
    <tr>
      <td>5001713</td>
      <td>-231</td>
      <td>22</td>
      <td>-10.5</td>
      <td>6.493587</td>
      <td>-21</td>
      <td>0</td>
      <td>-10.5</td>
    </tr>
  </tbody>
</table>
</div>



하나의 `SK_ID_BUREAU` 고유 키에 대한 다양한 통계 값으로 **right** 데이터프레임을 생성했습니다.

**right** 데이터프레임을 bureau 데이터프레임에 병합(merge) 해주도록 하겠습니다.


```python
merged = pd.merge(bureau, right, on='SK_ID_BUREAU', how='left')
```

병합은 **left: bureau, right: right, 기준컬럼: SK_ID_BUREAU, how:는 bureau 기준이니 left 옵션**을 주도록 하였습니다.

**내가 병합을 잘 했는지 안했는지 확인하는 Tip!**

bureau가 합치기 전 row의 갯수와, 합친 후의 row의 갯수가 동일해야합니다. (bureau 기준으로 합쳤을 경우)


```python
bureau.shape[0], merged.shape[0]
```




    (1716428, 1716428)




```python
# merge가 성공적으로 되었는지 체크 코드
# 해당 셀을 실행시 에러가 없어야 합니다.
assert bureau.shape[0] == merged.shape[0]
```


```python
merged.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>SK_ID_BUREAU</th>
      <th>CREDIT_ACTIVE</th>
      <th>CREDIT_CURRENCY</th>
      <th>DAYS_CREDIT</th>
      <th>CREDIT_DAY_OVERDUE</th>
      <th>DAYS_CREDIT_ENDDATE</th>
      <th>DAYS_ENDDATE_FACT</th>
      <th>AMT_CREDIT_MAX_OVERDUE</th>
      <th>CNT_CREDIT_PROLONG</th>
      <th>...</th>
      <th>CREDIT_TYPE</th>
      <th>DAYS_CREDIT_UPDATE</th>
      <th>AMT_ANNUITY</th>
      <th>sum</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>215354</td>
      <td>5714462</td>
      <td>Closed</td>
      <td>currency 1</td>
      <td>-497</td>
      <td>0</td>
      <td>-153.0</td>
      <td>-153.0</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>Consumer credit</td>
      <td>-131</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>1</td>
      <td>215354</td>
      <td>5714463</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-208</td>
      <td>0</td>
      <td>1075.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>Credit card</td>
      <td>-20</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2</td>
      <td>215354</td>
      <td>5714464</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-203</td>
      <td>0</td>
      <td>528.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>Consumer credit</td>
      <td>-16</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>3</td>
      <td>215354</td>
      <td>5714465</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-203</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>Credit card</td>
      <td>-16</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>215354</td>
      <td>5714466</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-629</td>
      <td>0</td>
      <td>1197.0</td>
      <td>NaN</td>
      <td>77674.5</td>
      <td>0</td>
      <td>...</td>
      <td>Consumer credit</td>
      <td>-21</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 24 columns</p>
</div>



동일하다면, 잘 합쳐 졌습니다!!!

### STEP 2. 이제는 merged 데이터프레임을 all_data에 합쳐 보겠습니다.


```python
merged.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>SK_ID_BUREAU</th>
      <th>CREDIT_ACTIVE</th>
      <th>CREDIT_CURRENCY</th>
      <th>DAYS_CREDIT</th>
      <th>CREDIT_DAY_OVERDUE</th>
      <th>DAYS_CREDIT_ENDDATE</th>
      <th>DAYS_ENDDATE_FACT</th>
      <th>AMT_CREDIT_MAX_OVERDUE</th>
      <th>CNT_CREDIT_PROLONG</th>
      <th>...</th>
      <th>CREDIT_TYPE</th>
      <th>DAYS_CREDIT_UPDATE</th>
      <th>AMT_ANNUITY</th>
      <th>sum</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>215354</td>
      <td>5714462</td>
      <td>Closed</td>
      <td>currency 1</td>
      <td>-497</td>
      <td>0</td>
      <td>-153.0</td>
      <td>-153.0</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>Consumer credit</td>
      <td>-131</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>1</td>
      <td>215354</td>
      <td>5714463</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-208</td>
      <td>0</td>
      <td>1075.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>Credit card</td>
      <td>-20</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2</td>
      <td>215354</td>
      <td>5714464</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-203</td>
      <td>0</td>
      <td>528.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>Consumer credit</td>
      <td>-16</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>3</td>
      <td>215354</td>
      <td>5714465</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-203</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>Credit card</td>
      <td>-16</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>215354</td>
      <td>5714466</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-629</td>
      <td>0</td>
      <td>1197.0</td>
      <td>NaN</td>
      <td>77674.5</td>
      <td>0</td>
      <td>...</td>
      <td>Consumer credit</td>
      <td>-21</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 24 columns</p>
</div>




```python
all_data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>...</th>
      <th>FLAG_DOCUMENT_18</th>
      <th>FLAG_DOCUMENT_19</th>
      <th>FLAG_DOCUMENT_20</th>
      <th>FLAG_DOCUMENT_21</th>
      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>
      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>
      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>
      <th>AMT_REQ_CREDIT_BUREAU_MON</th>
      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>
      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100002</td>
      <td>1.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>406597.5</td>
      <td>24700.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100003</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>270000.0</td>
      <td>1293502.5</td>
      <td>35698.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100004</td>
      <td>0.0</td>
      <td>Revolving loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>67500.0</td>
      <td>135000.0</td>
      <td>6750.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100006</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>312682.5</td>
      <td>29686.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100007</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>121500.0</td>
      <td>513000.0</td>
      <td>21865.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 122 columns</p>
</div>



`SK_ID_CURR`을 기준으로 합치면 유효할 것 같습니다.


```python
all_data.shape, merged.shape
```




    ((356255, 122), (1716428, 24))



**all_data**를 기준으로 **merged**데이터프레임을 병합하되, all_data를 기준으로 병합합니다.


```python
all_data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>...</th>
      <th>FLAG_DOCUMENT_18</th>
      <th>FLAG_DOCUMENT_19</th>
      <th>FLAG_DOCUMENT_20</th>
      <th>FLAG_DOCUMENT_21</th>
      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>
      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>
      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>
      <th>AMT_REQ_CREDIT_BUREAU_MON</th>
      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>
      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100002</td>
      <td>1.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>406597.5</td>
      <td>24700.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100003</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>270000.0</td>
      <td>1293502.5</td>
      <td>35698.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100004</td>
      <td>0.0</td>
      <td>Revolving loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>67500.0</td>
      <td>135000.0</td>
      <td>6750.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100006</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>312682.5</td>
      <td>29686.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100007</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>121500.0</td>
      <td>513000.0</td>
      <td>21865.5</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 122 columns</p>
</div>




```python
merged.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>SK_ID_BUREAU</th>
      <th>CREDIT_ACTIVE</th>
      <th>CREDIT_CURRENCY</th>
      <th>DAYS_CREDIT</th>
      <th>CREDIT_DAY_OVERDUE</th>
      <th>DAYS_CREDIT_ENDDATE</th>
      <th>DAYS_ENDDATE_FACT</th>
      <th>AMT_CREDIT_MAX_OVERDUE</th>
      <th>CNT_CREDIT_PROLONG</th>
      <th>...</th>
      <th>CREDIT_TYPE</th>
      <th>DAYS_CREDIT_UPDATE</th>
      <th>AMT_ANNUITY</th>
      <th>sum</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>215354</td>
      <td>5714462</td>
      <td>Closed</td>
      <td>currency 1</td>
      <td>-497</td>
      <td>0</td>
      <td>-153.0</td>
      <td>-153.0</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>Consumer credit</td>
      <td>-131</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>1</td>
      <td>215354</td>
      <td>5714463</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-208</td>
      <td>0</td>
      <td>1075.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>Credit card</td>
      <td>-20</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>2</td>
      <td>215354</td>
      <td>5714464</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-203</td>
      <td>0</td>
      <td>528.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>Consumer credit</td>
      <td>-16</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>3</td>
      <td>215354</td>
      <td>5714465</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-203</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>...</td>
      <td>Credit card</td>
      <td>-16</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>215354</td>
      <td>5714466</td>
      <td>Active</td>
      <td>currency 1</td>
      <td>-629</td>
      <td>0</td>
      <td>1197.0</td>
      <td>NaN</td>
      <td>77674.5</td>
      <td>0</td>
      <td>...</td>
      <td>Consumer credit</td>
      <td>-21</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 24 columns</p>
</div>




```python
merged.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 1716428 entries, 0 to 1716427
    Data columns (total 24 columns):
    SK_ID_CURR                int64
    SK_ID_BUREAU              int64
    CREDIT_ACTIVE             object
    CREDIT_CURRENCY           object
    DAYS_CREDIT               int64
    CREDIT_DAY_OVERDUE        int64
    DAYS_CREDIT_ENDDATE       float64
    DAYS_ENDDATE_FACT         float64
    AMT_CREDIT_MAX_OVERDUE    float64
    CNT_CREDIT_PROLONG        int64
    AMT_CREDIT_SUM            float64
    AMT_CREDIT_SUM_DEBT       float64
    AMT_CREDIT_SUM_LIMIT      float64
    AMT_CREDIT_SUM_OVERDUE    float64
    CREDIT_TYPE               object
    DAYS_CREDIT_UPDATE        int64
    AMT_ANNUITY               float64
    sum                       float64
    count                     float64
    mean                      float64
    std                       float64
    min                       float64
    max                       float64
    median                    float64
    dtypes: float64(15), int64(6), object(3)
    memory usage: 327.4+ MB
    

위의 `merged` 데이터 를 보면 **SK_ID_CURR** 컬럼에 중복 값이 들어가 있습니다.

병합할 때, `SK_ID_CURR` 키로 병합하게 되면, 꼬일 수 있습니다.

병합할 키 값은 항상 **고유**하게 유지해야합니다.

그러면, merged 데이터를 `SK_ID_CURR` 컬럼에 대하여 groupby 하여 수치형 데이터 / 카테고리형 데이터로 구분하여 전처리 해주도록 하겠습니다.


```python
numerical_cols = merged.select_dtypes(exclude='object').columns.to_list()
categorical_cols = merged.select_dtypes(include='object').columns.to_list()
```


```python
numerical_cols
```




    ['SK_ID_CURR',
     'SK_ID_BUREAU',
     'DAYS_CREDIT',
     'CREDIT_DAY_OVERDUE',
     'DAYS_CREDIT_ENDDATE',
     'DAYS_ENDDATE_FACT',
     'AMT_CREDIT_MAX_OVERDUE',
     'CNT_CREDIT_PROLONG',
     'AMT_CREDIT_SUM',
     'AMT_CREDIT_SUM_DEBT',
     'AMT_CREDIT_SUM_LIMIT',
     'AMT_CREDIT_SUM_OVERDUE',
     'DAYS_CREDIT_UPDATE',
     'AMT_ANNUITY',
     'sum',
     'count',
     'mean',
     'std',
     'min',
     'max',
     'median']



`SK_ID_BUREAU` 컬럼은 index 형 컬럼 이므로, 제거하도록 합니다. 통계 수치를 통합할 때 id 값은 제거 한 후 통계값을 산출합니다.


```python
numerical_cols.remove('SK_ID_BUREAU')
```


```python
numerical_cols
```




    ['SK_ID_CURR',
     'DAYS_CREDIT',
     'CREDIT_DAY_OVERDUE',
     'DAYS_CREDIT_ENDDATE',
     'DAYS_ENDDATE_FACT',
     'AMT_CREDIT_MAX_OVERDUE',
     'CNT_CREDIT_PROLONG',
     'AMT_CREDIT_SUM',
     'AMT_CREDIT_SUM_DEBT',
     'AMT_CREDIT_SUM_LIMIT',
     'AMT_CREDIT_SUM_OVERDUE',
     'DAYS_CREDIT_UPDATE',
     'AMT_ANNUITY',
     'sum',
     'count',
     'mean',
     'std',
     'min',
     'max',
     'median']




```python
categorical_cols
```




    ['CREDIT_ACTIVE', 'CREDIT_CURRENCY', 'CREDIT_TYPE']



`SK_ID_CURR` 키를 categorical_col 리스트에 추가 합니다. 나중에 이 키가 누락되면 병합시 키 오류가 발생합니다.


```python
categorical_cols.append('SK_ID_CURR')
```


```python
categorical_cols
```




    ['CREDIT_ACTIVE', 'CREDIT_CURRENCY', 'CREDIT_TYPE', 'SK_ID_CURR']



이제 **numerical** 데이터와 **categorical** 데이터를 각각 `SK_ID_CURR`로 groupby 하여 전처리를 진행하고,

numerical_right, categorical_right 변수에 임시로 데이터프레임을 저장하도록 하겠습니다.

**numerical_right**: 수치형 데이터 만 groupby


```python
numerical_right = merged[numerical_cols] \
            .groupby('SK_ID_CURR') \
            .agg(['sum', 'count', 'mean', 'std', 'min', 'max', 'median']).reset_index()
print(numerical_right.shape)
numerical_right.head()
```

    (305811, 134)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>SK_ID_CURR</th>
      <th colspan="7" halign="left">DAYS_CREDIT</th>
      <th colspan="2" halign="left">CREDIT_DAY_OVERDUE</th>
      <th>...</th>
      <th colspan="3" halign="left">max</th>
      <th colspan="7" halign="left">median</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>sum</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
      <th>sum</th>
      <th>count</th>
      <th>...</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
      <th>sum</th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100001</td>
      <td>-5145</td>
      <td>7</td>
      <td>-735.000000</td>
      <td>489.942514</td>
      <td>-1572</td>
      <td>-49</td>
      <td>-857.0</td>
      <td>0</td>
      <td>7</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-82.5</td>
      <td>7</td>
      <td>-11.785714</td>
      <td>8.025258</td>
      <td>-25.5</td>
      <td>-0.5</td>
      <td>-14.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100002</td>
      <td>-6992</td>
      <td>8</td>
      <td>-874.000000</td>
      <td>431.451040</td>
      <td>-1437</td>
      <td>-103</td>
      <td>-1042.5</td>
      <td>0</td>
      <td>8</td>
      <td>...</td>
      <td>-32.0</td>
      <td>0.0</td>
      <td>-18.5</td>
      <td>-175.0</td>
      <td>8</td>
      <td>-21.875000</td>
      <td>12.176529</td>
      <td>-39.5</td>
      <td>-1.5</td>
      <td>-26.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100003</td>
      <td>-5603</td>
      <td>4</td>
      <td>-1400.750000</td>
      <td>909.826128</td>
      <td>-2586</td>
      <td>-606</td>
      <td>-1205.5</td>
      <td>0</td>
      <td>4</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100004</td>
      <td>-1734</td>
      <td>2</td>
      <td>-867.000000</td>
      <td>649.124025</td>
      <td>-1326</td>
      <td>-408</td>
      <td>-867.0</td>
      <td>0</td>
      <td>2</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100005</td>
      <td>-572</td>
      <td>3</td>
      <td>-190.666667</td>
      <td>162.297053</td>
      <td>-373</td>
      <td>-62</td>
      <td>-137.0</td>
      <td>0</td>
      <td>3</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-9.0</td>
      <td>3</td>
      <td>-3.000000</td>
      <td>2.645751</td>
      <td>-6.0</td>
      <td>-1.0</td>
      <td>-2.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 134 columns</p>
</div>



**categorical_right**: 카테고리 데이터 만 groupby


```python
categorical_right = merged[categorical_cols] \
            .groupby('SK_ID_CURR') \
            .agg(['size', 'nunique']).reset_index()
print(categorical_right.shape)
categorical_right.head()
```

    (305811, 7)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>SK_ID_CURR</th>
      <th colspan="2" halign="left">CREDIT_ACTIVE</th>
      <th colspan="2" halign="left">CREDIT_CURRENCY</th>
      <th colspan="2" halign="left">CREDIT_TYPE</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>size</th>
      <th>nunique</th>
      <th>size</th>
      <th>nunique</th>
      <th>size</th>
      <th>nunique</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100001</td>
      <td>7</td>
      <td>2</td>
      <td>7</td>
      <td>1</td>
      <td>7</td>
      <td>1</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100002</td>
      <td>8</td>
      <td>2</td>
      <td>8</td>
      <td>1</td>
      <td>8</td>
      <td>2</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100003</td>
      <td>4</td>
      <td>2</td>
      <td>4</td>
      <td>1</td>
      <td>4</td>
      <td>2</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100004</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100005</td>
      <td>3</td>
      <td>2</td>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>



### Q1. all_data 기준으로 right 데이터프레임을 병합해 주세요

all_data를 기준으로 right 데이터프레임을 병합하고, all_data 변수에 다시 할당해 주세요


```python
# 여기에 코드를 입력해 주세요 #
all_data = pd.merge(all_data, numerical_right, on='SK_ID_CURR', how='left')
all_data = pd.merge(all_data, categorical_right, on='SK_ID_CURR', how='left')
###############################
all_data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>...</th>
      <th>(median, std)</th>
      <th>(median, min)</th>
      <th>(median, max)</th>
      <th>(median, median)</th>
      <th>(CREDIT_ACTIVE, size)</th>
      <th>(CREDIT_ACTIVE, nunique)</th>
      <th>(CREDIT_CURRENCY, size)</th>
      <th>(CREDIT_CURRENCY, nunique)</th>
      <th>(CREDIT_TYPE, size)</th>
      <th>(CREDIT_TYPE, nunique)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100002</td>
      <td>1.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>406597.5</td>
      <td>24700.5</td>
      <td>...</td>
      <td>12.176529</td>
      <td>-39.5</td>
      <td>-1.5</td>
      <td>-26.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100003</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>270000.0</td>
      <td>1293502.5</td>
      <td>35698.5</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100004</td>
      <td>0.0</td>
      <td>Revolving loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>67500.0</td>
      <td>135000.0</td>
      <td>6750.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100006</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>312682.5</td>
      <td>29686.5</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100007</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>121500.0</td>
      <td>513000.0</td>
      <td>21865.5</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 261 columns</p>
</div>




```python
# 검증코드
# 본 코드셀을 실행 시켜 에러가 발생하지 않아야 합니다.
assert all_data.shape == (356255, 261)
```


```python
Image('data/home_credit.png')
```




    
![png](output_64_0.png)
    



### STEP 3. POS_CASH_balance 전처리 및 병합

자, 이번에는 **POS_CASH_balance**데이터를 **all_data**에 병합해보겠습니다.


```python
pos_cash_balance = pd.read_csv('data/POS_CASH_balance.csv')
print(pos_cash_balance.shape)
pos_cash_balance.head()
```

    (10001358, 8)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_PREV</th>
      <th>SK_ID_CURR</th>
      <th>MONTHS_BALANCE</th>
      <th>CNT_INSTALMENT</th>
      <th>CNT_INSTALMENT_FUTURE</th>
      <th>NAME_CONTRACT_STATUS</th>
      <th>SK_DPD</th>
      <th>SK_DPD_DEF</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1803195</td>
      <td>182943</td>
      <td>-31</td>
      <td>48.0</td>
      <td>45.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1715348</td>
      <td>367990</td>
      <td>-33</td>
      <td>36.0</td>
      <td>35.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1784872</td>
      <td>397406</td>
      <td>-32</td>
      <td>12.0</td>
      <td>9.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>1903291</td>
      <td>269225</td>
      <td>-35</td>
      <td>48.0</td>
      <td>42.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>2341044</td>
      <td>334279</td>
      <td>-35</td>
      <td>36.0</td>
      <td>35.0</td>
      <td>Active</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>




```python
all_data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>...</th>
      <th>(median, std)</th>
      <th>(median, min)</th>
      <th>(median, max)</th>
      <th>(median, median)</th>
      <th>(CREDIT_ACTIVE, size)</th>
      <th>(CREDIT_ACTIVE, nunique)</th>
      <th>(CREDIT_CURRENCY, size)</th>
      <th>(CREDIT_CURRENCY, nunique)</th>
      <th>(CREDIT_TYPE, size)</th>
      <th>(CREDIT_TYPE, nunique)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100002</td>
      <td>1.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>406597.5</td>
      <td>24700.5</td>
      <td>...</td>
      <td>12.176529</td>
      <td>-39.5</td>
      <td>-1.5</td>
      <td>-26.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100003</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>270000.0</td>
      <td>1293502.5</td>
      <td>35698.5</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100004</td>
      <td>0.0</td>
      <td>Revolving loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>67500.0</td>
      <td>135000.0</td>
      <td>6750.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100006</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>312682.5</td>
      <td>29686.5</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100007</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>121500.0</td>
      <td>513000.0</td>
      <td>21865.5</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 261 columns</p>
</div>




```python
pos_cash_balance.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 10001358 entries, 0 to 10001357
    Data columns (total 8 columns):
    SK_ID_PREV               int64
    SK_ID_CURR               int64
    MONTHS_BALANCE           int64
    CNT_INSTALMENT           float64
    CNT_INSTALMENT_FUTURE    float64
    NAME_CONTRACT_STATUS     object
    SK_DPD                   int64
    SK_DPD_DEF               int64
    dtypes: float64(2), int64(5), object(1)
    memory usage: 610.4+ MB
    

### Q2. pos_cash_balance 데이터를 `SK_ID_CURR` 기준으로 group 하고, 다음 6개의 column에 대하여 aggregate 합니다.

- sum, mean, std, min, max, median
- groupby 한 데이터프레임은 **right** 에 할당합니다.


```python
# 여기에 코드를 입력해 주세요 #
right = pos_cash_balance.groupby(['SK_ID_CURR']) \
            .agg(['sum', 'mean', 'std', 'min', 'max', 'median']).reset_index()    
###############################
right.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>SK_ID_CURR</th>
      <th colspan="6" halign="left">SK_ID_PREV</th>
      <th colspan="3" halign="left">MONTHS_BALANCE</th>
      <th>...</th>
      <th colspan="4" halign="left">SK_DPD</th>
      <th colspan="6" halign="left">SK_DPD_DEF</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>sum</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
      <th>sum</th>
      <th>mean</th>
      <th>std</th>
      <th>...</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
      <th>sum</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100001</td>
      <td>14256401</td>
      <td>1.584045e+06</td>
      <td>254189.675833</td>
      <td>1369693</td>
      <td>1851984</td>
      <td>1369693.0</td>
      <td>-653</td>
      <td>-72.555556</td>
      <td>20.863312</td>
      <td>...</td>
      <td>2.333333</td>
      <td>0</td>
      <td>7</td>
      <td>0.0</td>
      <td>7</td>
      <td>0.777778</td>
      <td>2.333333</td>
      <td>0</td>
      <td>7</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100002</td>
      <td>19737542</td>
      <td>1.038818e+06</td>
      <td>0.000000</td>
      <td>1038818</td>
      <td>1038818</td>
      <td>1038818.0</td>
      <td>-190</td>
      <td>-10.000000</td>
      <td>5.627314</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100003</td>
      <td>64334628</td>
      <td>2.297665e+06</td>
      <td>329593.011850</td>
      <td>1810518</td>
      <td>2636178</td>
      <td>2396755.0</td>
      <td>-1226</td>
      <td>-43.785714</td>
      <td>24.640162</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100004</td>
      <td>6256056</td>
      <td>1.564014e+06</td>
      <td>0.000000</td>
      <td>1564014</td>
      <td>1564014</td>
      <td>1564014.0</td>
      <td>-102</td>
      <td>-25.500000</td>
      <td>1.290994</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100005</td>
      <td>27452425</td>
      <td>2.495675e+06</td>
      <td>0.000000</td>
      <td>2495675</td>
      <td>2495675</td>
      <td>2495675.0</td>
      <td>-220</td>
      <td>-20.000000</td>
      <td>3.316625</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 37 columns</p>
</div>




```python
# 검증코드
# 본 코드셀을 실행 시켜 에러가 발생하지 않아야 합니다.

assert right.shape == (337252, 37)
```


```python
all_data_2 = all_data.copy()
```

### Q3. right 데이터프레임을 all_data에 병합합니다.

- 기준 컬럼은 `SK_ID_CURR` 입니다.
- 병합된 컬럼은 all_data에 할당합니다.


```python
# 여기에 코드를 입력해 주세요 #
all_data = pd.merge(all_data, right, on='SK_ID_CURR', how='left')
###############################
all_data.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>...</th>
      <th>(SK_DPD, std)</th>
      <th>(SK_DPD, min)</th>
      <th>(SK_DPD, max)</th>
      <th>(SK_DPD, median)</th>
      <th>(SK_DPD_DEF, sum)</th>
      <th>(SK_DPD_DEF, mean)</th>
      <th>(SK_DPD_DEF, std)</th>
      <th>(SK_DPD_DEF, min)</th>
      <th>(SK_DPD_DEF, max)</th>
      <th>(SK_DPD_DEF, median)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100002</td>
      <td>1.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>406597.5</td>
      <td>24700.5</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100003</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>270000.0</td>
      <td>1293502.5</td>
      <td>35698.5</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100004</td>
      <td>0.0</td>
      <td>Revolving loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>67500.0</td>
      <td>135000.0</td>
      <td>6750.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100006</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>312682.5</td>
      <td>29686.5</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100007</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>121500.0</td>
      <td>513000.0</td>
      <td>21865.5</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 297 columns</p>
</div>




```python
# 검증코드
# 본 코드셀을 실행 시켜 에러가 발생하지 않아야 합니다.
assert all_data.shape == (356255, 297)
```

위에서 진행했던 방식과 동일한 방식으로 다른 파일에도 적용해 볼 수 있습니다.

더 높은 점수 획득을 위해서는 **다양한 데이터**, **많은 데이터**가 있다면, 도움이 될 것 입니다.

하지만, 반복되는 코드가 많으니, 나머지는 여러분들에게 맡기겠습니다. 추가로 스스로 해보고 싶으신 분들은 다른 데이터를 병합해보는 연습을 많이 해보시길 추천합니다!

## 시각화

### Q4. 간단한 시각화를 통해 우리가 예측해야할 데이터 샘플의 차이를 살펴 봅니다.

- 시각화 대상 컬럼: `TARGET` (예측값)
    
데이터의 불균형도를 확인합니다.


```python
plt.figure(figsize = (7, 7))
# 코드를 입력해 주세요
sns.countplot(x='TARGET', data=train)
plt.title('Loans Repayed')
plt.show()
```


    
![png](output_80_0.png)
    


## 문자형 컬럼에 대한 처리 (수치형 컬럼 변환)


```python
# 카테고리형 (문자형) 컬럼만 뽑아서 보겠습니다.
cat_cols = all_data.select_dtypes(include='object').columns
all_data[cat_cols].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>NAME_TYPE_SUITE</th>
      <th>NAME_INCOME_TYPE</th>
      <th>NAME_EDUCATION_TYPE</th>
      <th>NAME_FAMILY_STATUS</th>
      <th>NAME_HOUSING_TYPE</th>
      <th>OCCUPATION_TYPE</th>
      <th>WEEKDAY_APPR_PROCESS_START</th>
      <th>ORGANIZATION_TYPE</th>
      <th>FONDKAPREMONT_MODE</th>
      <th>HOUSETYPE_MODE</th>
      <th>WALLSMATERIAL_MODE</th>
      <th>EMERGENCYSTATE_MODE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>Unaccompanied</td>
      <td>Working</td>
      <td>Secondary / secondary special</td>
      <td>Single / not married</td>
      <td>House / apartment</td>
      <td>Laborers</td>
      <td>WEDNESDAY</td>
      <td>Business Entity Type 3</td>
      <td>reg oper account</td>
      <td>block of flats</td>
      <td>Stone, brick</td>
      <td>No</td>
    </tr>
    <tr>
      <td>1</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>Family</td>
      <td>State servant</td>
      <td>Higher education</td>
      <td>Married</td>
      <td>House / apartment</td>
      <td>Core staff</td>
      <td>MONDAY</td>
      <td>School</td>
      <td>reg oper account</td>
      <td>block of flats</td>
      <td>Block</td>
      <td>No</td>
    </tr>
    <tr>
      <td>2</td>
      <td>Revolving loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>Unaccompanied</td>
      <td>Working</td>
      <td>Secondary / secondary special</td>
      <td>Single / not married</td>
      <td>House / apartment</td>
      <td>Laborers</td>
      <td>MONDAY</td>
      <td>Government</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>3</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>Unaccompanied</td>
      <td>Working</td>
      <td>Secondary / secondary special</td>
      <td>Civil marriage</td>
      <td>House / apartment</td>
      <td>Laborers</td>
      <td>WEDNESDAY</td>
      <td>Business Entity Type 3</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>Unaccompanied</td>
      <td>Working</td>
      <td>Secondary / secondary special</td>
      <td>Single / not married</td>
      <td>House / apartment</td>
      <td>Core staff</td>
      <td>THURSDAY</td>
      <td>Religion</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



### Q5. 카테고리형 컬럼에 대하여 LabelEncoding을 해주세요. 

- 어떤 패키지/라이브러리를 활용하든 상관없습니다.
- 문자형 컬럼을 숫자형으로 인코딩합니다.


```python
# 여기에 코드를 입력해 주세요 #
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

all_data[cat_cols] = all_data[cat_cols].astype(str)
all_data[cat_cols] = all_data[cat_cols].apply(le.fit_transform)

all_data[cat_cols].head()
###############################
# 결과 예시
all_data[cat_cols].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>NAME_TYPE_SUITE</th>
      <th>NAME_INCOME_TYPE</th>
      <th>NAME_EDUCATION_TYPE</th>
      <th>NAME_FAMILY_STATUS</th>
      <th>NAME_HOUSING_TYPE</th>
      <th>OCCUPATION_TYPE</th>
      <th>WEEKDAY_APPR_PROCESS_START</th>
      <th>ORGANIZATION_TYPE</th>
      <th>FONDKAPREMONT_MODE</th>
      <th>HOUSETYPE_MODE</th>
      <th>WALLSMATERIAL_MODE</th>
      <th>EMERGENCYSTATE_MODE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>6</td>
      <td>7</td>
      <td>4</td>
      <td>3</td>
      <td>1</td>
      <td>8</td>
      <td>6</td>
      <td>5</td>
      <td>3</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>39</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>6</td>
      <td>7</td>
      <td>4</td>
      <td>3</td>
      <td>1</td>
      <td>8</td>
      <td>1</td>
      <td>11</td>
      <td>0</td>
      <td>1</td>
      <td>7</td>
      <td>2</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>6</td>
      <td>7</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>8</td>
      <td>6</td>
      <td>5</td>
      <td>0</td>
      <td>1</td>
      <td>7</td>
      <td>2</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>6</td>
      <td>7</td>
      <td>4</td>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>4</td>
      <td>37</td>
      <td>0</td>
      <td>1</td>
      <td>7</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>



### 다음 STEP: 빈 값(NaN)에 대한 처리를 진행합니다. 빈 값은 임의로 모든 값을 '0'으로 채워주겠습니다.


```python
all_data = all_data.fillna(0)
```


```python
all_data.isnull().sum()
```




    SK_ID_CURR              0
    TARGET                  0
    NAME_CONTRACT_TYPE      0
    CODE_GENDER             0
    FLAG_OWN_CAR            0
                           ..
    (SK_DPD_DEF, mean)      0
    (SK_DPD_DEF, std)       0
    (SK_DPD_DEF, min)       0
    (SK_DPD_DEF, max)       0
    (SK_DPD_DEF, median)    0
    Length: 297, dtype: int64



## train / test 의 데이터를 분할합니다.


```python
train_data = all_data[:len(train)]
test_data = all_data[len(train):]
test_data = test_data.drop('TARGET', 1)
```


```python
# 검증코드
assert train_data.shape[0] == train.shape[0]
```


```python
# 검증코드
assert test_data.shape[0] == test.shape[0]
```

**train_data, test_data로 분할**해 주었습니다. 이제는 검증세트까지 만들어 보겠습니다.

### Q6. train_test_split 을 활용하여, 데이터를 분할해 주세요

train_test_split()의 다음 2개의 파라미터에 대하여 고정 값으로 입력해 주세요


```python
from sklearn.model_selection import train_test_split
```


```python
random_state=34
test_size=0.2
```


```python
# 여기에 코드를 입력해 주세요 #
x_train, x_valid, y_train, y_valid = train_test_split(#코드 입력
                                                      train_data.drop('TARGET', 1), 
                                                      train_data['TARGET'], 
                                                      stratify=train_data['TARGET'], 
                                                      random_state=random_state, 
                                                      test_size=test_size)
###############################
```

## 모델링


```python
from sklearn.ensemble import RandomForestClassifier
```

### Q7. RandomForestClassifier 앙상블 모델을 활용하여 모델을 학습합니다.


```python
# 코드를 입력해 주세요 #
model = RandomForestClassifier(n_estimators=500, max_depth=6, n_jobs=-1)
random_forest_model_fitted = model.fit(x_train, y_train)
########################
```

아래 코드는 각각의 상위 20개의 모델 예측에 영향을 준 **feature**들을 살펴봅니다.

**importance**가 높을 수록 모델 예측에 많은 기여가 되는 컬럼입니다.


```python
fi = pd.DataFrame(list(zip(x_train.columns, model.feature_importances_))).sort_values(by=1, ascending=False).reset_index(drop=True).head(20)
fi.columns = ['feature', 'importance']
fi
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature</th>
      <th>importance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>EXT_SOURCE_2</td>
      <td>0.160928</td>
    </tr>
    <tr>
      <td>1</td>
      <td>EXT_SOURCE_3</td>
      <td>0.115736</td>
    </tr>
    <tr>
      <td>2</td>
      <td>EXT_SOURCE_1</td>
      <td>0.039500</td>
    </tr>
    <tr>
      <td>3</td>
      <td>(DAYS_CREDIT, median)</td>
      <td>0.031559</td>
    </tr>
    <tr>
      <td>4</td>
      <td>(DAYS_CREDIT, mean)</td>
      <td>0.031123</td>
    </tr>
    <tr>
      <td>5</td>
      <td>DAYS_BIRTH</td>
      <td>0.028970</td>
    </tr>
    <tr>
      <td>6</td>
      <td>(DAYS_CREDIT_UPDATE, median)</td>
      <td>0.020913</td>
    </tr>
    <tr>
      <td>7</td>
      <td>(DAYS_CREDIT, max)</td>
      <td>0.017683</td>
    </tr>
    <tr>
      <td>8</td>
      <td>NAME_EDUCATION_TYPE</td>
      <td>0.015948</td>
    </tr>
    <tr>
      <td>9</td>
      <td>(DAYS_CREDIT_ENDDATE, median)</td>
      <td>0.015230</td>
    </tr>
    <tr>
      <td>10</td>
      <td>(DAYS_CREDIT_UPDATE, mean)</td>
      <td>0.014170</td>
    </tr>
    <tr>
      <td>11</td>
      <td>NAME_INCOME_TYPE</td>
      <td>0.014002</td>
    </tr>
    <tr>
      <td>12</td>
      <td>DAYS_EMPLOYED</td>
      <td>0.011659</td>
    </tr>
    <tr>
      <td>13</td>
      <td>(DAYS_CREDIT_ENDDATE, sum)</td>
      <td>0.011387</td>
    </tr>
    <tr>
      <td>14</td>
      <td>(SK_DPD_DEF, mean)</td>
      <td>0.011383</td>
    </tr>
    <tr>
      <td>15</td>
      <td>AMT_GOODS_PRICE</td>
      <td>0.010654</td>
    </tr>
    <tr>
      <td>16</td>
      <td>(DAYS_CREDIT_ENDDATE, mean)</td>
      <td>0.010363</td>
    </tr>
    <tr>
      <td>17</td>
      <td>(AMT_CREDIT_MAX_OVERDUE, max)</td>
      <td>0.010264</td>
    </tr>
    <tr>
      <td>18</td>
      <td>(AMT_CREDIT_MAX_OVERDUE, sum)</td>
      <td>0.009801</td>
    </tr>
    <tr>
      <td>19</td>
      <td>(DAYS_CREDIT, min)</td>
      <td>0.009569</td>
    </tr>
  </tbody>
</table>
</div>



이번 대회에서는 제출 기준을 `TARGET`이 1이 될 확률을 제출하는 것입니다.

predict() 함수는 class를 예측해주지만, predict_proba()는 각각의 class에 대한 확률값을 return합니다.

우리는 1이될 확률을 구해야합니다.


```python
pred = model.predict_proba(test_data)
# 1이 될 확률을 구합니다.
pred[:, 1]
```




    array([0.08281809, 0.12250228, 0.05997663, ..., 0.06619179, 0.05734652,
           0.10617588])



**sample_submission** 파일에 우리가 예측한 정답값을 입력합니다.


```python
submission = pd.read_csv('data/sample_submission.csv')
# 정답 입력
submission['TARGET'] = pred[:, 1]
submission.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100001</td>
      <td>0.082818</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100005</td>
      <td>0.122502</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100013</td>
      <td>0.059977</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100028</td>
      <td>0.047601</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100038</td>
      <td>0.123701</td>
    </tr>
  </tbody>
</table>
</div>



submission 파일을 csv 포맷의 파일로 내보냅니다.

대부분의 Kaggle 대회에서는 csv 파일 제출을 요구합니다.


```python
from datetime import datetime

timestring = datetime.now().strftime('%m-%d-%H-%M-%S')
filename = '{}-homecredit-submit.csv'.format(timestring)
submission.to_csv(filename, index=False)
```

이제 날짜와 시간이 입혀진 정답 파일(.csv)이 나왔습니다.

**Late Submission**을 해보고, 우리의 점수가 리더보드에 어느 수준인지 확인합니다.

제출은 [이곳](https://www.kaggle.com/c/home-credit-default-risk/submit)에서 Late Submission 클릭 후 - 자신이 예측한 모델의 예측값이 들어있는 .csv 파일 업로드 - 제출

### Extra Q. 전처리, 모델 변경 등을 통해서 더 나은 예측 모델을 만들어서 캐글 상위권에 도전합니다 (0.73 이상)

hint: RandomForestClassifier 단일 모델로도 0.73 이상 달성할 수 있습니다.
다만, hyperparameter를 튜닝해야합니다.

* max_features, max_depth, n_estimators를 유심히 살펴보세요
* [도큐먼트](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)


```python
# 이곳에 코드를 입력해 주세요
model_2 = RandomForestClassifier(n_estimators=100, 
                               max_features=0.2,
                               max_depth=8,
                               n_jobs=-1)

random_forest_model_fitted_2 = model_2.fit(x_train, y_train)

final_pred_2 = model_2.predict_proba(test_data)

submission = pd.read_csv('data/sample_submission.csv')
# 정답 입력
submission['TARGET'] = final_pred_2[:, 1]

# submission 파일 생성
timestring = datetime.now().strftime('%m-%d-%H-%M-%S')
filename = '{}-homecredit-submit.csv'.format(timestring)
submission.to_csv(filename, index=False)

```

## 아래 추가로 코드 작성 해봤으나 만족할 만한 결과는 나오지 않았습니다.


```python
all_data_2.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>...</th>
      <th>(median, std)</th>
      <th>(median, min)</th>
      <th>(median, max)</th>
      <th>(median, median)</th>
      <th>(CREDIT_ACTIVE, size)</th>
      <th>(CREDIT_ACTIVE, nunique)</th>
      <th>(CREDIT_CURRENCY, size)</th>
      <th>(CREDIT_CURRENCY, nunique)</th>
      <th>(CREDIT_TYPE, size)</th>
      <th>(CREDIT_TYPE, nunique)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100002</td>
      <td>1.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>406597.5</td>
      <td>24700.5</td>
      <td>...</td>
      <td>12.176529</td>
      <td>-39.5</td>
      <td>-1.5</td>
      <td>-26.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100003</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>270000.0</td>
      <td>1293502.5</td>
      <td>35698.5</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100004</td>
      <td>0.0</td>
      <td>Revolving loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>67500.0</td>
      <td>135000.0</td>
      <td>6750.0</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100006</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>312682.5</td>
      <td>29686.5</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100007</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>121500.0</td>
      <td>513000.0</td>
      <td>21865.5</td>
      <td>...</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 261 columns</p>
</div>




```python
# pos_cash_balance 데이터를 SK_ID_CURR 기준으로 group
# 수치형 데이터 / 카테고리형 데이터로 구분하여 전처리 
numerical_cols = pos_cash_balance.select_dtypes(exclude='object').columns.to_list()
categorical_cols = pos_cash_balance.select_dtypes(include='object').columns.to_list()
```


```python
numerical_cols
```




    ['SK_ID_PREV',
     'SK_ID_CURR',
     'MONTHS_BALANCE',
     'CNT_INSTALMENT',
     'CNT_INSTALMENT_FUTURE',
     'SK_DPD',
     'SK_DPD_DEF']




```python
# SK_ID_PREV 제거
numerical_cols.remove('SK_ID_PREV')
```


```python
numerical_cols
```




    ['SK_ID_CURR',
     'MONTHS_BALANCE',
     'CNT_INSTALMENT',
     'CNT_INSTALMENT_FUTURE',
     'SK_DPD',
     'SK_DPD_DEF']




```python
categorical_cols
```




    ['NAME_CONTRACT_STATUS']




```python
# SK_ID_CURR 추가
categorical_cols.append('SK_ID_CURR')
```


```python
categorical_cols
```




    ['NAME_CONTRACT_STATUS', 'SK_ID_CURR']




```python
numerical_right = pos_cash_balance[numerical_cols] \
            .groupby(['SK_ID_CURR']) \
            .agg(['sum', 'mean', 'std', 'min', 'max', 'median']).reset_index()    
print(numerical_right.shape)
numerical_right.head()
```

    (337252, 31)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>SK_ID_CURR</th>
      <th colspan="6" halign="left">MONTHS_BALANCE</th>
      <th colspan="3" halign="left">CNT_INSTALMENT</th>
      <th>...</th>
      <th colspan="4" halign="left">SK_DPD</th>
      <th colspan="6" halign="left">SK_DPD_DEF</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>sum</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
      <th>sum</th>
      <th>mean</th>
      <th>std</th>
      <th>...</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
      <th>sum</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>max</th>
      <th>median</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100001</td>
      <td>-653</td>
      <td>-72.555556</td>
      <td>20.863312</td>
      <td>-96</td>
      <td>-53</td>
      <td>-57.0</td>
      <td>36.0</td>
      <td>4.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>2.333333</td>
      <td>0</td>
      <td>7</td>
      <td>0.0</td>
      <td>7</td>
      <td>0.777778</td>
      <td>2.333333</td>
      <td>0</td>
      <td>7</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100002</td>
      <td>-190</td>
      <td>-10.000000</td>
      <td>5.627314</td>
      <td>-19</td>
      <td>-1</td>
      <td>-10.0</td>
      <td>456.0</td>
      <td>24.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100003</td>
      <td>-1226</td>
      <td>-43.785714</td>
      <td>24.640162</td>
      <td>-77</td>
      <td>-18</td>
      <td>-26.5</td>
      <td>283.0</td>
      <td>10.107143</td>
      <td>2.806597</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100004</td>
      <td>-102</td>
      <td>-25.500000</td>
      <td>1.290994</td>
      <td>-27</td>
      <td>-24</td>
      <td>-25.5</td>
      <td>15.0</td>
      <td>3.750000</td>
      <td>0.500000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100005</td>
      <td>-220</td>
      <td>-20.000000</td>
      <td>3.316625</td>
      <td>-25</td>
      <td>-15</td>
      <td>-20.0</td>
      <td>117.0</td>
      <td>11.700000</td>
      <td>0.948683</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
      <td>0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0</td>
      <td>0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div>




```python
categorical_right = pos_cash_balance[categorical_cols] \
            .groupby('SK_ID_CURR') \
            .agg(['size', 'nunique']).reset_index()
print(categorical_right.shape)
categorical_right.head()
```

    (337252, 3)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>SK_ID_CURR</th>
      <th colspan="2" halign="left">NAME_CONTRACT_STATUS</th>
    </tr>
    <tr>
      <th></th>
      <th></th>
      <th>size</th>
      <th>nunique</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100001</td>
      <td>9</td>
      <td>2</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100002</td>
      <td>19</td>
      <td>1</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100003</td>
      <td>28</td>
      <td>2</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100004</td>
      <td>4</td>
      <td>2</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100005</td>
      <td>11</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>




```python
all_data_2 = pd.merge(all_data_2, numerical_right, on='SK_ID_CURR', how='left')
all_data_2 = pd.merge(all_data_2, categorical_right, on='SK_ID_CURR', how='left')
```


```python
all_data_2.shape
```




    (356255, 293)




```python
all_data_2.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>CODE_GENDER</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>...</th>
      <th>(SK_DPD, max)</th>
      <th>(SK_DPD, median)</th>
      <th>(SK_DPD_DEF, sum)</th>
      <th>(SK_DPD_DEF, mean)</th>
      <th>(SK_DPD_DEF, std)</th>
      <th>(SK_DPD_DEF, min)</th>
      <th>(SK_DPD_DEF, max)</th>
      <th>(SK_DPD_DEF, median)</th>
      <th>(NAME_CONTRACT_STATUS, size)</th>
      <th>(NAME_CONTRACT_STATUS, nunique)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100002</td>
      <td>1.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>202500.0</td>
      <td>406597.5</td>
      <td>24700.5</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>19.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100003</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>N</td>
      <td>0</td>
      <td>270000.0</td>
      <td>1293502.5</td>
      <td>35698.5</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>28.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100004</td>
      <td>0.0</td>
      <td>Revolving loans</td>
      <td>M</td>
      <td>Y</td>
      <td>Y</td>
      <td>0</td>
      <td>67500.0</td>
      <td>135000.0</td>
      <td>6750.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100006</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>F</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>135000.0</td>
      <td>312682.5</td>
      <td>29686.5</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>21.0</td>
      <td>3.0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100007</td>
      <td>0.0</td>
      <td>Cash loans</td>
      <td>M</td>
      <td>N</td>
      <td>Y</td>
      <td>0</td>
      <td>121500.0</td>
      <td>513000.0</td>
      <td>21865.5</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>66.0</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 293 columns</p>
</div>




```python
all_data_2.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Int64Index: 356255 entries, 0 to 356254
    Columns: 293 entries, SK_ID_CURR to (NAME_CONTRACT_STATUS, nunique)
    dtypes: float64(237), int64(40), object(16)
    memory usage: 799.1+ MB
    


```python
# 카테고리형 col 중 속성값이 2개 이하인 데이터는 label 인코딩
# 2개 이상인 데이터는 one hot encoding 진행
le = LabelEncoder()
le_count = 0
# Iterate through the columns
for col in all_data_2:
    if all_data_2[col].dtype == 'object':
        # If 2 or fewer unique categories
        if len(list(all_data_2[col].unique())) <= 2:
            # Train on the training data
            le.fit(all_data_2[col])
            # Transform both training and testing data
            all_data_2[col] = le.transform(all_data_2[col])
            
            # Keep track of how many columns were label encoded
            le_count += 1
           
print('%d columns were label encoded.' % le_count)
```

    3 columns were label encoded.
    


```python
# 2개 이상인 데이터는 one hot encoding 진행
all_data_2 = pd.get_dummies(all_data_2)

display(all_data_2.shape)
```


    (356255, 414)



```python
def missing_values_table(df):
        mis_val = df.isnull().sum()
        
        mis_val_percent = 100 * df.isnull().sum() / len(df)
        
        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)
        
        mis_val_table_ren_columns = mis_val_table.rename(
        columns = {0 : 'Missing Values', 1 : '% of Total Values'})
        
        mis_val_table_ren_columns = mis_val_table_ren_columns[
            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(
        '% of Total Values', ascending=False).round(1)
        
        print ("The dataset has " + str(df.shape[1]) + " columns.\n"      
            "There are " + str(mis_val_table_ren_columns.shape[0]) +
              " columns that have missing values.")
        
        return mis_val_table_ren_columns
missing_values_table(all_data_2)
```

    The dataset has 414 columns.
    There are 233 columns that have missing values.
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Missing Values</th>
      <th>% of Total Values</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>(AMT_ANNUITY, std)</td>
      <td>263856</td>
      <td>74.1</td>
    </tr>
    <tr>
      <td>COMMONAREA_MODE</td>
      <td>248360</td>
      <td>69.7</td>
    </tr>
    <tr>
      <td>COMMONAREA_MEDI</td>
      <td>248360</td>
      <td>69.7</td>
    </tr>
    <tr>
      <td>COMMONAREA_AVG</td>
      <td>248360</td>
      <td>69.7</td>
    </tr>
    <tr>
      <td>NONLIVINGAPARTMENTS_MODE</td>
      <td>246861</td>
      <td>69.3</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>EXT_SOURCE_2</td>
      <td>668</td>
      <td>0.2</td>
    </tr>
    <tr>
      <td>AMT_GOODS_PRICE</td>
      <td>278</td>
      <td>0.1</td>
    </tr>
    <tr>
      <td>AMT_ANNUITY</td>
      <td>36</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>CNT_FAM_MEMBERS</td>
      <td>2</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>DAYS_LAST_PHONE_CHANGE</td>
      <td>1</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>233 rows × 2 columns</p>
</div>




```python
# 카테고리형 (문자형) 컬럼만 뽑아서 보겠습니다.
num_cols = all_data_2.select_dtypes(exclude='object').columns
all_data_2[num_cols].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>AMT_GOODS_PRICE</th>
      <th>...</th>
      <th>HOUSETYPE_MODE_terraced house</th>
      <th>WALLSMATERIAL_MODE_Block</th>
      <th>WALLSMATERIAL_MODE_Mixed</th>
      <th>WALLSMATERIAL_MODE_Monolithic</th>
      <th>WALLSMATERIAL_MODE_Others</th>
      <th>WALLSMATERIAL_MODE_Panel</th>
      <th>WALLSMATERIAL_MODE_Stone, brick</th>
      <th>WALLSMATERIAL_MODE_Wooden</th>
      <th>EMERGENCYSTATE_MODE_No</th>
      <th>EMERGENCYSTATE_MODE_Yes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>100002</td>
      <td>1.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>202500.0</td>
      <td>406597.5</td>
      <td>24700.5</td>
      <td>351000.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>100003</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>270000.0</td>
      <td>1293502.5</td>
      <td>35698.5</td>
      <td>1129500.0</td>
      <td>...</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>100004</td>
      <td>0.0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>67500.0</td>
      <td>135000.0</td>
      <td>6750.0</td>
      <td>135000.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>100006</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>135000.0</td>
      <td>312682.5</td>
      <td>29686.5</td>
      <td>297000.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>100007</td>
      <td>0.0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>121500.0</td>
      <td>513000.0</td>
      <td>21865.5</td>
      <td>513000.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 414 columns</p>
</div>




```python
for col in all_data_2[num_cols]:
    print(col, all_data_2[col].isna().sum())
```

    SK_ID_CURR 0
    TARGET 48744
    NAME_CONTRACT_TYPE 0
    FLAG_OWN_CAR 0
    FLAG_OWN_REALTY 0
    CNT_CHILDREN 0
    AMT_INCOME_TOTAL 0
    AMT_CREDIT 0
    AMT_ANNUITY 36
    AMT_GOODS_PRICE 278
    REGION_POPULATION_RELATIVE 0
    DAYS_BIRTH 0
    DAYS_EMPLOYED 0
    DAYS_REGISTRATION 0
    DAYS_ID_PUBLISH 0
    OWN_CAR_AGE 235241
    FLAG_MOBIL 0
    FLAG_EMP_PHONE 0
    FLAG_WORK_PHONE 0
    FLAG_CONT_MOBILE 0
    FLAG_PHONE 0
    FLAG_EMAIL 0
    CNT_FAM_MEMBERS 2
    REGION_RATING_CLIENT 0
    REGION_RATING_CLIENT_W_CITY 0
    HOUR_APPR_PROCESS_START 0
    REG_REGION_NOT_LIVE_REGION 0
    REG_REGION_NOT_WORK_REGION 0
    LIVE_REGION_NOT_WORK_REGION 0
    REG_CITY_NOT_LIVE_CITY 0
    REG_CITY_NOT_WORK_CITY 0
    LIVE_CITY_NOT_WORK_CITY 0
    EXT_SOURCE_1 193910
    EXT_SOURCE_2 668
    EXT_SOURCE_3 69633
    APARTMENTS_AVG 179948
    BASEMENTAREA_AVG 207584
    YEARS_BEGINEXPLUATATION_AVG 172863
    YEARS_BUILD_AVG 236306
    COMMONAREA_AVG 248360
    ELEVATORS_AVG 189080
    ENTRANCES_AVG 178407
    FLOORSMAX_AVG 176341
    FLOORSMIN_AVG 241108
    LANDAREA_AVG 210844
    LIVINGAPARTMENTS_AVG 242979
    LIVINGAREA_AVG 177902
    NONLIVINGAPARTMENTS_AVG 246861
    NONLIVINGAREA_AVG 195766
    APARTMENTS_MODE 179948
    BASEMENTAREA_MODE 207584
    YEARS_BEGINEXPLUATATION_MODE 172863
    YEARS_BUILD_MODE 236306
    COMMONAREA_MODE 248360
    ELEVATORS_MODE 189080
    ENTRANCES_MODE 178407
    FLOORSMAX_MODE 176341
    FLOORSMIN_MODE 241108
    LANDAREA_MODE 210844
    LIVINGAPARTMENTS_MODE 242979
    LIVINGAREA_MODE 177902
    NONLIVINGAPARTMENTS_MODE 246861
    NONLIVINGAREA_MODE 195766
    APARTMENTS_MEDI 179948
    BASEMENTAREA_MEDI 207584
    YEARS_BEGINEXPLUATATION_MEDI 172863
    YEARS_BUILD_MEDI 236306
    COMMONAREA_MEDI 248360
    ELEVATORS_MEDI 189080
    ENTRANCES_MEDI 178407
    FLOORSMAX_MEDI 176341
    FLOORSMIN_MEDI 241108
    LANDAREA_MEDI 210844
    LIVINGAPARTMENTS_MEDI 242979
    LIVINGAREA_MEDI 177902
    NONLIVINGAPARTMENTS_MEDI 246861
    NONLIVINGAREA_MEDI 195766
    TOTALAREA_MODE 171055
    OBS_30_CNT_SOCIAL_CIRCLE 1050
    DEF_30_CNT_SOCIAL_CIRCLE 1050
    OBS_60_CNT_SOCIAL_CIRCLE 1050
    DEF_60_CNT_SOCIAL_CIRCLE 1050
    DAYS_LAST_PHONE_CHANGE 1
    FLAG_DOCUMENT_2 0
    FLAG_DOCUMENT_3 0
    FLAG_DOCUMENT_4 0
    FLAG_DOCUMENT_5 0
    FLAG_DOCUMENT_6 0
    FLAG_DOCUMENT_7 0
    FLAG_DOCUMENT_8 0
    FLAG_DOCUMENT_9 0
    FLAG_DOCUMENT_10 0
    FLAG_DOCUMENT_11 0
    FLAG_DOCUMENT_12 0
    FLAG_DOCUMENT_13 0
    FLAG_DOCUMENT_14 0
    FLAG_DOCUMENT_15 0
    FLAG_DOCUMENT_16 0
    FLAG_DOCUMENT_17 0
    FLAG_DOCUMENT_18 0
    FLAG_DOCUMENT_19 0
    FLAG_DOCUMENT_20 0
    FLAG_DOCUMENT_21 0
    AMT_REQ_CREDIT_BUREAU_HOUR 47568
    AMT_REQ_CREDIT_BUREAU_DAY 47568
    AMT_REQ_CREDIT_BUREAU_WEEK 47568
    AMT_REQ_CREDIT_BUREAU_MON 47568
    AMT_REQ_CREDIT_BUREAU_QRT 47568
    AMT_REQ_CREDIT_BUREAU_YEAR 47568
    ('DAYS_CREDIT', 'sum') 50444
    ('DAYS_CREDIT', 'count') 50444
    ('DAYS_CREDIT', 'mean') 50444
    ('DAYS_CREDIT', 'std') 91964
    ('DAYS_CREDIT', 'min') 50444
    ('DAYS_CREDIT', 'max') 50444
    ('DAYS_CREDIT', 'median') 50444
    ('CREDIT_DAY_OVERDUE', 'sum') 50444
    ('CREDIT_DAY_OVERDUE', 'count') 50444
    ('CREDIT_DAY_OVERDUE', 'mean') 50444
    ('CREDIT_DAY_OVERDUE', 'std') 91964
    ('CREDIT_DAY_OVERDUE', 'min') 50444
    ('CREDIT_DAY_OVERDUE', 'max') 50444
    ('CREDIT_DAY_OVERDUE', 'median') 50444
    ('DAYS_CREDIT_ENDDATE', 'sum') 50444
    ('DAYS_CREDIT_ENDDATE', 'count') 50444
    ('DAYS_CREDIT_ENDDATE', 'mean') 53029
    ('DAYS_CREDIT_ENDDATE', 'std') 97343
    ('DAYS_CREDIT_ENDDATE', 'min') 53029
    ('DAYS_CREDIT_ENDDATE', 'max') 53029
    ('DAYS_CREDIT_ENDDATE', 'median') 53029
    ('DAYS_ENDDATE_FACT', 'sum') 50444
    ('DAYS_ENDDATE_FACT', 'count') 50444
    ('DAYS_ENDDATE_FACT', 'mean') 88100
    ('DAYS_ENDDATE_FACT', 'std') 149639
    ('DAYS_ENDDATE_FACT', 'min') 88100
    ('DAYS_ENDDATE_FACT', 'max') 88100
    ('DAYS_ENDDATE_FACT', 'median') 88100
    ('AMT_CREDIT_MAX_OVERDUE', 'sum') 50444
    ('AMT_CREDIT_MAX_OVERDUE', 'count') 50444
    ('AMT_CREDIT_MAX_OVERDUE', 'mean') 143284
    ('AMT_CREDIT_MAX_OVERDUE', 'std') 219686
    ('AMT_CREDIT_MAX_OVERDUE', 'min') 143284
    ('AMT_CREDIT_MAX_OVERDUE', 'max') 143284
    ('AMT_CREDIT_MAX_OVERDUE', 'median') 143284
    ('CNT_CREDIT_PROLONG', 'sum') 50444
    ('CNT_CREDIT_PROLONG', 'count') 50444
    ('CNT_CREDIT_PROLONG', 'mean') 50444
    ('CNT_CREDIT_PROLONG', 'std') 91964
    ('CNT_CREDIT_PROLONG', 'min') 50444
    ('CNT_CREDIT_PROLONG', 'max') 50444
    ('CNT_CREDIT_PROLONG', 'median') 50444
    ('AMT_CREDIT_SUM', 'sum') 50444
    ('AMT_CREDIT_SUM', 'count') 50444
    ('AMT_CREDIT_SUM', 'mean') 50446
    ('AMT_CREDIT_SUM', 'std') 91965
    ('AMT_CREDIT_SUM', 'min') 50446
    ('AMT_CREDIT_SUM', 'max') 50446
    ('AMT_CREDIT_SUM', 'median') 50446
    ('AMT_CREDIT_SUM_DEBT', 'sum') 50444
    ('AMT_CREDIT_SUM_DEBT', 'count') 50444
    ('AMT_CREDIT_SUM_DEBT', 'mean') 58816
    ('AMT_CREDIT_SUM_DEBT', 'std') 107105
    ('AMT_CREDIT_SUM_DEBT', 'min') 58816
    ('AMT_CREDIT_SUM_DEBT', 'max') 58816
    ('AMT_CREDIT_SUM_DEBT', 'median') 58816
    ('AMT_CREDIT_SUM_LIMIT', 'sum') 50444
    ('AMT_CREDIT_SUM_LIMIT', 'count') 50444
    ('AMT_CREDIT_SUM_LIMIT', 'mean') 75752
    ('AMT_CREDIT_SUM_LIMIT', 'std') 134454
    ('AMT_CREDIT_SUM_LIMIT', 'min') 75752
    ('AMT_CREDIT_SUM_LIMIT', 'max') 75752
    ('AMT_CREDIT_SUM_LIMIT', 'median') 75752
    ('AMT_CREDIT_SUM_OVERDUE', 'sum') 50444
    ('AMT_CREDIT_SUM_OVERDUE', 'count') 50444
    ('AMT_CREDIT_SUM_OVERDUE', 'mean') 50444
    ('AMT_CREDIT_SUM_OVERDUE', 'std') 91964
    ('AMT_CREDIT_SUM_OVERDUE', 'min') 50444
    ('AMT_CREDIT_SUM_OVERDUE', 'max') 50444
    ('AMT_CREDIT_SUM_OVERDUE', 'median') 50444
    ('DAYS_CREDIT_UPDATE', 'sum') 50444
    ('DAYS_CREDIT_UPDATE', 'count') 50444
    ('DAYS_CREDIT_UPDATE', 'mean') 50444
    ('DAYS_CREDIT_UPDATE', 'std') 91964
    ('DAYS_CREDIT_UPDATE', 'min') 50444
    ('DAYS_CREDIT_UPDATE', 'max') 50444
    ('DAYS_CREDIT_UPDATE', 'median') 50444
    ('AMT_ANNUITY', 'sum') 50444
    ('AMT_ANNUITY', 'count') 50444
    ('AMT_ANNUITY', 'mean') 238031
    ('AMT_ANNUITY', 'std') 263856
    ('AMT_ANNUITY', 'min') 238031
    ('AMT_ANNUITY', 'max') 238031
    ('AMT_ANNUITY', 'median') 238031
    ('sum', 'sum') 50444
    ('sum', 'count') 50444
    ('sum', 'mean') 221713
    ('sum', 'std') 239353
    ('sum', 'min') 221713
    ('sum', 'max') 221713
    ('sum', 'median') 221713
    ('count', 'sum') 50444
    ('count', 'count') 50444
    ('count', 'mean') 221713
    ('count', 'std') 239353
    ('count', 'min') 221713
    ('count', 'max') 221713
    ('count', 'median') 221713
    ('mean', 'sum') 50444
    ('mean', 'count') 50444
    ('mean', 'mean') 221713
    ('mean', 'std') 239353
    ('mean', 'min') 221713
    ('mean', 'max') 221713
    ('mean', 'median') 221713
    ('std', 'sum') 50444
    ('std', 'count') 50444
    ('std', 'mean') 222002
    ('std', 'std') 239751
    ('std', 'min') 222002
    ('std', 'max') 222002
    ('std', 'median') 222002
    ('min', 'sum') 50444
    ('min', 'count') 50444
    ('min', 'mean') 221713
    ('min', 'std') 239353
    ('min', 'min') 221713
    ('min', 'max') 221713
    ('min', 'median') 221713
    ('max', 'sum') 50444
    ('max', 'count') 50444
    ('max', 'mean') 221713
    ('max', 'std') 239353
    ('max', 'min') 221713
    ('max', 'max') 221713
    ('max', 'median') 221713
    ('median', 'sum') 50444
    ('median', 'count') 50444
    ('median', 'mean') 221713
    ('median', 'std') 239353
    ('median', 'min') 221713
    ('median', 'max') 221713
    ('median', 'median') 221713
    ('CREDIT_ACTIVE', 'size') 50444
    ('CREDIT_ACTIVE', 'nunique') 50444
    ('CREDIT_CURRENCY', 'size') 50444
    ('CREDIT_CURRENCY', 'nunique') 50444
    ('CREDIT_TYPE', 'size') 50444
    ('CREDIT_TYPE', 'nunique') 50444
    ('MONTHS_BALANCE', 'sum') 19003
    ('MONTHS_BALANCE', 'mean') 19003
    ('MONTHS_BALANCE', 'std') 19375
    ('MONTHS_BALANCE', 'min') 19003
    ('MONTHS_BALANCE', 'max') 19003
    ('MONTHS_BALANCE', 'median') 19003
    ('CNT_INSTALMENT', 'sum') 19003
    ('CNT_INSTALMENT', 'mean') 19031
    ('CNT_INSTALMENT', 'std') 19397
    ('CNT_INSTALMENT', 'min') 19031
    ('CNT_INSTALMENT', 'max') 19031
    ('CNT_INSTALMENT', 'median') 19031
    ('CNT_INSTALMENT_FUTURE', 'sum') 19003
    ('CNT_INSTALMENT_FUTURE', 'mean') 19031
    ('CNT_INSTALMENT_FUTURE', 'std') 19397
    ('CNT_INSTALMENT_FUTURE', 'min') 19031
    ('CNT_INSTALMENT_FUTURE', 'max') 19031
    ('CNT_INSTALMENT_FUTURE', 'median') 19031
    ('SK_DPD', 'sum') 19003
    ('SK_DPD', 'mean') 19003
    ('SK_DPD', 'std') 19375
    ('SK_DPD', 'min') 19003
    ('SK_DPD', 'max') 19003
    ('SK_DPD', 'median') 19003
    ('SK_DPD_DEF', 'sum') 19003
    ('SK_DPD_DEF', 'mean') 19003
    ('SK_DPD_DEF', 'std') 19375
    ('SK_DPD_DEF', 'min') 19003
    ('SK_DPD_DEF', 'max') 19003
    ('SK_DPD_DEF', 'median') 19003
    ('NAME_CONTRACT_STATUS', 'size') 19003
    ('NAME_CONTRACT_STATUS', 'nunique') 19003
    CODE_GENDER_F 0
    CODE_GENDER_M 0
    CODE_GENDER_XNA 0
    NAME_TYPE_SUITE_Children 0
    NAME_TYPE_SUITE_Family 0
    NAME_TYPE_SUITE_Group of people 0
    NAME_TYPE_SUITE_Other_A 0
    NAME_TYPE_SUITE_Other_B 0
    NAME_TYPE_SUITE_Spouse, partner 0
    NAME_TYPE_SUITE_Unaccompanied 0
    NAME_INCOME_TYPE_Businessman 0
    NAME_INCOME_TYPE_Commercial associate 0
    NAME_INCOME_TYPE_Maternity leave 0
    NAME_INCOME_TYPE_Pensioner 0
    NAME_INCOME_TYPE_State servant 0
    NAME_INCOME_TYPE_Student 0
    NAME_INCOME_TYPE_Unemployed 0
    NAME_INCOME_TYPE_Working 0
    NAME_EDUCATION_TYPE_Academic degree 0
    NAME_EDUCATION_TYPE_Higher education 0
    NAME_EDUCATION_TYPE_Incomplete higher 0
    NAME_EDUCATION_TYPE_Lower secondary 0
    NAME_EDUCATION_TYPE_Secondary / secondary special 0
    NAME_FAMILY_STATUS_Civil marriage 0
    NAME_FAMILY_STATUS_Married 0
    NAME_FAMILY_STATUS_Separated 0
    NAME_FAMILY_STATUS_Single / not married 0
    NAME_FAMILY_STATUS_Unknown 0
    NAME_FAMILY_STATUS_Widow 0
    NAME_HOUSING_TYPE_Co-op apartment 0
    NAME_HOUSING_TYPE_House / apartment 0
    NAME_HOUSING_TYPE_Municipal apartment 0
    NAME_HOUSING_TYPE_Office apartment 0
    NAME_HOUSING_TYPE_Rented apartment 0
    NAME_HOUSING_TYPE_With parents 0
    OCCUPATION_TYPE_Accountants 0
    OCCUPATION_TYPE_Cleaning staff 0
    OCCUPATION_TYPE_Cooking staff 0
    OCCUPATION_TYPE_Core staff 0
    OCCUPATION_TYPE_Drivers 0
    OCCUPATION_TYPE_HR staff 0
    OCCUPATION_TYPE_High skill tech staff 0
    OCCUPATION_TYPE_IT staff 0
    OCCUPATION_TYPE_Laborers 0
    OCCUPATION_TYPE_Low-skill Laborers 0
    OCCUPATION_TYPE_Managers 0
    OCCUPATION_TYPE_Medicine staff 0
    OCCUPATION_TYPE_Private service staff 0
    OCCUPATION_TYPE_Realty agents 0
    OCCUPATION_TYPE_Sales staff 0
    OCCUPATION_TYPE_Secretaries 0
    OCCUPATION_TYPE_Security staff 0
    OCCUPATION_TYPE_Waiters/barmen staff 0
    WEEKDAY_APPR_PROCESS_START_FRIDAY 0
    WEEKDAY_APPR_PROCESS_START_MONDAY 0
    WEEKDAY_APPR_PROCESS_START_SATURDAY 0
    WEEKDAY_APPR_PROCESS_START_SUNDAY 0
    WEEKDAY_APPR_PROCESS_START_THURSDAY 0
    WEEKDAY_APPR_PROCESS_START_TUESDAY 0
    WEEKDAY_APPR_PROCESS_START_WEDNESDAY 0
    ORGANIZATION_TYPE_Advertising 0
    ORGANIZATION_TYPE_Agriculture 0
    ORGANIZATION_TYPE_Bank 0
    ORGANIZATION_TYPE_Business Entity Type 1 0
    ORGANIZATION_TYPE_Business Entity Type 2 0
    ORGANIZATION_TYPE_Business Entity Type 3 0
    ORGANIZATION_TYPE_Cleaning 0
    ORGANIZATION_TYPE_Construction 0
    ORGANIZATION_TYPE_Culture 0
    ORGANIZATION_TYPE_Electricity 0
    ORGANIZATION_TYPE_Emergency 0
    ORGANIZATION_TYPE_Government 0
    ORGANIZATION_TYPE_Hotel 0
    ORGANIZATION_TYPE_Housing 0
    ORGANIZATION_TYPE_Industry: type 1 0
    ORGANIZATION_TYPE_Industry: type 10 0
    ORGANIZATION_TYPE_Industry: type 11 0
    ORGANIZATION_TYPE_Industry: type 12 0
    ORGANIZATION_TYPE_Industry: type 13 0
    ORGANIZATION_TYPE_Industry: type 2 0
    ORGANIZATION_TYPE_Industry: type 3 0
    ORGANIZATION_TYPE_Industry: type 4 0
    ORGANIZATION_TYPE_Industry: type 5 0
    ORGANIZATION_TYPE_Industry: type 6 0
    ORGANIZATION_TYPE_Industry: type 7 0
    ORGANIZATION_TYPE_Industry: type 8 0
    ORGANIZATION_TYPE_Industry: type 9 0
    ORGANIZATION_TYPE_Insurance 0
    ORGANIZATION_TYPE_Kindergarten 0
    ORGANIZATION_TYPE_Legal Services 0
    ORGANIZATION_TYPE_Medicine 0
    ORGANIZATION_TYPE_Military 0
    ORGANIZATION_TYPE_Mobile 0
    ORGANIZATION_TYPE_Other 0
    ORGANIZATION_TYPE_Police 0
    ORGANIZATION_TYPE_Postal 0
    ORGANIZATION_TYPE_Realtor 0
    ORGANIZATION_TYPE_Religion 0
    ORGANIZATION_TYPE_Restaurant 0
    ORGANIZATION_TYPE_School 0
    ORGANIZATION_TYPE_Security 0
    ORGANIZATION_TYPE_Security Ministries 0
    ORGANIZATION_TYPE_Self-employed 0
    ORGANIZATION_TYPE_Services 0
    ORGANIZATION_TYPE_Telecom 0
    ORGANIZATION_TYPE_Trade: type 1 0
    ORGANIZATION_TYPE_Trade: type 2 0
    ORGANIZATION_TYPE_Trade: type 3 0
    ORGANIZATION_TYPE_Trade: type 4 0
    ORGANIZATION_TYPE_Trade: type 5 0
    ORGANIZATION_TYPE_Trade: type 6 0
    ORGANIZATION_TYPE_Trade: type 7 0
    ORGANIZATION_TYPE_Transport: type 1 0
    ORGANIZATION_TYPE_Transport: type 2 0
    ORGANIZATION_TYPE_Transport: type 3 0
    ORGANIZATION_TYPE_Transport: type 4 0
    ORGANIZATION_TYPE_University 0
    ORGANIZATION_TYPE_XNA 0
    FONDKAPREMONT_MODE_not specified 0
    FONDKAPREMONT_MODE_org spec account 0
    FONDKAPREMONT_MODE_reg oper account 0
    FONDKAPREMONT_MODE_reg oper spec account 0
    HOUSETYPE_MODE_block of flats 0
    HOUSETYPE_MODE_specific housing 0
    HOUSETYPE_MODE_terraced house 0
    WALLSMATERIAL_MODE_Block 0
    WALLSMATERIAL_MODE_Mixed 0
    WALLSMATERIAL_MODE_Monolithic 0
    WALLSMATERIAL_MODE_Others 0
    WALLSMATERIAL_MODE_Panel 0
    WALLSMATERIAL_MODE_Stone, brick 0
    WALLSMATERIAL_MODE_Wooden 0
    EMERGENCYSTATE_MODE_No 0
    EMERGENCYSTATE_MODE_Yes 0
    


```python
all_data_Encoding = all_data_2.fillna(0)
```


```python
missing_values_table(all_data_Encoding)
```

    The dataset has 414 columns.
    There are 0 columns that have missing values.
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Missing Values</th>
      <th>% of Total Values</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>




```python
# 피처 스케일링
from sklearn.preprocessing import MinMaxScaler
def encoder(df):
    scaler = MinMaxScaler()
    numerical = all_data_Encoding.select_dtypes(exclude = ["object"]).columns
    features_transform = pd.DataFrame(data= df)
    features_transform[numerical] = scaler.fit_transform(df[numerical])
    display(features_transform.head(n = 5))
    return df
all_data_scale = encoder(all_data_Encoding)
```


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>SK_ID_CURR</th>
      <th>TARGET</th>
      <th>NAME_CONTRACT_TYPE</th>
      <th>FLAG_OWN_CAR</th>
      <th>FLAG_OWN_REALTY</th>
      <th>CNT_CHILDREN</th>
      <th>AMT_INCOME_TOTAL</th>
      <th>AMT_CREDIT</th>
      <th>AMT_ANNUITY</th>
      <th>AMT_GOODS_PRICE</th>
      <th>...</th>
      <th>HOUSETYPE_MODE_terraced house</th>
      <th>WALLSMATERIAL_MODE_Block</th>
      <th>WALLSMATERIAL_MODE_Mixed</th>
      <th>WALLSMATERIAL_MODE_Monolithic</th>
      <th>WALLSMATERIAL_MODE_Others</th>
      <th>WALLSMATERIAL_MODE_Panel</th>
      <th>WALLSMATERIAL_MODE_Stone, brick</th>
      <th>WALLSMATERIAL_MODE_Wooden</th>
      <th>EMERGENCYSTATE_MODE_No</th>
      <th>EMERGENCYSTATE_MODE_Yes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.000003</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.001512</td>
      <td>0.090287</td>
      <td>0.095729</td>
      <td>0.086667</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.000006</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.002089</td>
      <td>0.311736</td>
      <td>0.138353</td>
      <td>0.278889</td>
      <td>...</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.000008</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.000358</td>
      <td>0.022472</td>
      <td>0.026160</td>
      <td>0.033333</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.000014</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.000935</td>
      <td>0.066837</td>
      <td>0.115053</td>
      <td>0.073333</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.000017</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.000819</td>
      <td>0.116854</td>
      <td>0.084742</td>
      <td>0.126667</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 414 columns</p>
</div>



```python
# 다중공선성 검정
corrs = all_data_scale.corr()
threshold = 0.8
above_threshold_vars = {}
for col in corrs:
    above_threshold_vars[col] = list(corrs.index[corrs[col]> threshold])
len(above_threshold_vars)
```




    414




```python
cols_to_remove = []
cols_seen = []
cols_to_remove_pair = []
for key, value in above_threshold_vars.items():
    cols_seen.append(key)
    for x in value :
        if x == key:
            next
        else:
            if x not in cols_seen:
                cols_to_remove.append(x)
                cols_to_remove_pair.append(key)
cols_to_remove = list(set(cols_to_remove))
```


```python
all_data_removed = all_data_scale.drop(columns=cols_to_remove)
all_data_removed.shape
```




    (356255, 266)




```python
train_data_1 = all_data_removed[:len(train)]
test_data_1 = all_data_removed[len(train):]
test_data_1 = test_data_1.drop('TARGET', 1)
```


```python
# 검증코드
assert train_data_1.shape[0] == train.shape[0]
```


```python
# 검증코드
assert test_data_1.shape[0] == test.shape[0]
```


```python
# 여기에 코드를 입력해 주세요 #
x_train, x_valid, y_train, y_valid = train_test_split(#코드 입력
                                                      train_data_1.drop('TARGET', 1), 
                                                      train_data_1['TARGET'], 
                                                      stratify=train_data_1['TARGET'], 
                                                      random_state=random_state, 
                                                      test_size=test_size)
```


```python
# 기존의 X_train, y_train, X_test, y_test의 형태 확인
print("Number transactions x_train dataset: ", x_train.shape)
print("Number transactions y_train dataset: ", y_train.shape)
print("Number transactions x_valid dataset: ", x_valid.shape)
print("Number transactions y_valid dataset: ", y_valid.shape)
```

    Number transactions x_train dataset:  (246008, 265)
    Number transactions y_train dataset:  (246008,)
    Number transactions x_valid dataset:  (61503, 265)
    Number transactions y_valid dataset:  (61503,)
    


```python
# SMOTE을 이용해서 Oversampling
from imblearn.over_sampling import SMOTE
print("Before OverSampling, counts of label '1': {}".format(sum(y_train == 1))) # y_train 중 레이블 값이 1인 데이터의 개수
print("Before OverSampling, counts of label '0': {} \n".format(sum(y_train == 0))) # y_train 중 레이블 값이 0 인 데이터의 개수

sm = SMOTE(random_state = 42, ratio = 0.3) # SMOTE 알고리즘, 비율 증가
X_train_res, y_train_res = sm.fit_sample(x_train, y_train.ravel()) # Over Sampling 진행

print("After OverSampling, counts of label '1': {}".format(sum(y_train_res==1)))
print("After OverSampling, counts of label '0': {}".format(sum(y_train_res==0)))
```

    Before OverSampling, counts of label '1': 19860
    Before OverSampling, counts of label '0': 226148 
    
    After OverSampling, counts of label '1': 67844
    After OverSampling, counts of label '0': 226148
    


```python
print("Before OverSampling, the shape of x_train: {}".format(x_train.shape)) # SMOTE 적용 이전 데이터 형태
print("Before OverSampling, the shape of y_train: {}".format(y_train.shape)) # SMOTE 적용 이전 데이터 형태
print('After OverSampling, the shape of X_train_res: {}'.format(X_train_res.shape)) # SMOTE 적용 결과 확인
print('After OverSampling, the shape of y_train_res: {}'.format(y_train_res.shape)) # # SMOTE 적용 결과 확인
```

    Before OverSampling, the shape of x_train: (246008, 265)
    Before OverSampling, the shape of y_train: (246008,)
    After OverSampling, the shape of X_train_res: (293992, 265)
    After OverSampling, the shape of y_train_res: (293992,)
    


```python
# 이곳에 코드를 입력해 주세요
model_3 = RandomForestClassifier(n_estimators=100, 
                               max_features=0.2,
                               max_depth=8,
                               n_jobs=-1)

random_forest_model_fitted_3 = model_3.fit(X_train_res, y_train_res)

final_pred_3 = model_3.predict_proba(test_data_1)

submission = pd.read_csv('data/sample_submission.csv')
# 정답 입력
submission['TARGET'] = final_pred_3[:, 1]

# submission 파일 생성
timestring = datetime.now().strftime('%m-%d-%H-%M-%S')
filename = '{}-homecredit-submit.csv'.format(timestring)
submission.to_csv(filename, index=False)
```


```python

```
